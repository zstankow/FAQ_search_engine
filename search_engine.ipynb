{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e34c827-c8b5-443f-a1e1-834f0f1a4d1c",
   "metadata": {},
   "source": [
    "# Creating a simple search engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d870cba3-faa5-45b1-a7a4-3a1ca8fccd29",
   "metadata": {},
   "source": [
    "### Goals of this notebook\n",
    "\n",
    "1) Explore a few different ways we can implement a simple search engine for queries. The goal is that the user can type a query related to the zoomcamp course FAQ pages, and can receive a few results in order of their relevance. We will see how different methods yield different results and which are more effective in extracting the most relevant results. \n",
    "\n",
    "In this exercise we will look at both __Text Search and Semantic/Vector__ search methods. Note that both these methods are under the umbrella of the 'Bag of Words' method, which means that the order of the words has no meaning. This has obvious limitations and can be overcome with more advanced models like BERT. \n",
    "\n",
    "We can illustrate the difference in these methods with a small example:\n",
    "\n",
    "`query = 'I just discovered the course. Can I still join?'`\n",
    "\n",
    "In text search, we will find all the documents that contain words like 'discovered', 'course', 'join', etc. However, often the user forms a question that does not really match the documents. For example:\n",
    "\n",
    "`query = 'I just found out about the program. Can I still enroll?'`\n",
    "\n",
    "Semantically, both queries have the same meaning, but with text search we will not get good results. This is when a semantic/vector approach will perform much better. \n",
    "\n",
    "2) Understand the steps of getting relevant search results using more basic methods like CountVectorizer/TfidfVectorizer, and then slightly more sophisticated methods using singular value reduction (dimensionality reduction methods) like SVD and NMF to embed the vector and gain semantic meaning.\n",
    "\n",
    "Here is a quick breakdown of each of these methods:\n",
    "\n",
    "__Text search methods__:\n",
    "- create an instance of the Vectorizer (CV, Tfdif), fit_transform the documents to get document matrix (X), and transform the query (q)\n",
    "- calculate similarity score (with cosine similarity between X and q) and rank results\n",
    "\n",
    "__Semantic/Vector methods__:\n",
    "- create an instance of the Vectorizer (CV, Tfdif), fit_transform the documents to get document matrix (X), and transform the query (Q)\n",
    "- create an instance of the Embedder (SVD, NMF), fit_transform X to dense document matrix (X_emb), and transform Q to get dense query array (Q_emb)\n",
    "- calculate similarity score (with cosine similarity between X_emb and Q_emb) and rank results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15df5206-059b-4d4a-a35a-f857ab644555",
   "metadata": {},
   "source": [
    "### Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e435a393-7e56-4966-a375-6de0f1c940a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a865da7-a750-4682-bea0-e7b206d76977",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bf55624-b8a7-49c9-a678-dd13d22ba7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - Can I still join the course after the start date?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b4c5be1-1287-40d1-8b8e-4222c4498281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to dataframe\n",
    "df = pd.DataFrame(documents, columns=['course', 'section', 'question', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f5cd729-db88-42d7-ab0d-c0f3d8bd35cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>section</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - When will the course start?</td>\n",
       "      <td>The purpose of this document is to capture fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - What are the prerequisites for this c...</td>\n",
       "      <td>GitHub - DataTalksClub data-engineering-zoomca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - Can I still join the course after the...</td>\n",
       "      <td>Yes, even if you don't register, you're still ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - I have registered for the Data Engine...</td>\n",
       "      <td>You don't need it. You're accepted. You can al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - What can I do before the course starts?</td>\n",
       "      <td>You can start by installing and setting up all...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      course                           section  \\\n",
       "0  data-engineering-zoomcamp  General course-related questions   \n",
       "1  data-engineering-zoomcamp  General course-related questions   \n",
       "2  data-engineering-zoomcamp  General course-related questions   \n",
       "3  data-engineering-zoomcamp  General course-related questions   \n",
       "4  data-engineering-zoomcamp  General course-related questions   \n",
       "\n",
       "                                            question  \\\n",
       "0               Course - When will the course start?   \n",
       "1  Course - What are the prerequisites for this c...   \n",
       "2  Course - Can I still join the course after the...   \n",
       "3  Course - I have registered for the Data Engine...   \n",
       "4   Course - What can I do before the course starts?   \n",
       "\n",
       "                                                text  \n",
       "0  The purpose of this document is to capture fre...  \n",
       "1  GitHub - DataTalksClub data-engineering-zoomca...  \n",
       "2  Yes, even if you don't register, you're still ...  \n",
       "3  You don't need it. You're accepted. You can al...  \n",
       "4  You can start by installing and setting up all...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f296a0a-3604-41cb-a0f3-5f64e6d2dd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(948, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91784a3f-0781-4220-84fd-c5d97c28e286",
   "metadata": {},
   "source": [
    "## Text Search Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b3a36d-4185-4c22-9185-409f701ba3d2",
   "metadata": {},
   "source": [
    "### Using CountVectorizer from sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cabf5f-d38d-4859-99f8-1e2bce5cd1c5",
   "metadata": {},
   "source": [
    "From the dataframe `df` we see that we have 948 documents, each containing 4 different fields. We need to convert the text of each document to a numerical representation (to encode the document), in a process called vectorization. In vectorization, we turn the document into a vector with encodings. We are essentially creating a dictionary of all the words that appear in all our documents, and then assigning 1 or 0 if the document contains this word. This creates a document matrix, when the rows are each document (in our case, 948 rows) and the columns are the words/tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3db6d835-2008-482e-9177-38f143da42e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(stop_words='english', min_df=5) \n",
    "X = cv.fit_transform(df.text)\n",
    "names = cv.get_feature_names_out()\n",
    "df_docs = pd.DataFrame(X.toarray(), columns=names).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ce2c57-b451-48ad-a9b6-afabaeca1806",
   "metadata": {},
   "source": [
    "Notes about parameters in CV instance: \n",
    "\n",
    "__min_df__: only care about terms that appear in 5 documents (to avoid questions that are rarely asked or in nonEglish languages)\n",
    "__stop_words__: Stopwords are the words which occur frequently and don't provide any useful information. We define it as 'english' to recognize and remove all the English stop-words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0912e086-2748-4146-b5f7-75e26ad6285f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['01', '02', '03', ..., 'youtube', 'zip', 'zoomcamp'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cb5266-ec08-4540-a2a4-9b0d35650048",
   "metadata": {},
   "source": [
    "After fitting the `text` feature of the dataframe of documents, we can see our word dictionary using the CountVectorizer.get_feature_names_out(). It contains 1333 words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10751f50-0f77-4a42-a95c-ce143461675e",
   "metadata": {},
   "source": [
    "Our document matrix after using CountVectorizer:\n",
    "\n",
    "We can see that it is a sparse matrix, meaning that most of the values are 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed0b4982-cb7f-413a-a9cf-c2587f32395d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>y_val</th>\n",
       "      <th>yaml</th>\n",
       "      <th>year</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yellow_tripdata_2021</th>\n",
       "      <th>yes</th>\n",
       "      <th>yml</th>\n",
       "      <th>youtube</th>\n",
       "      <th>zip</th>\n",
       "      <th>zoomcamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>948 rows × 1333 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     01  02  03  04  05  06  09  10  100  11  ...  y_val  yaml  year  yellow  \\\n",
       "0     0   0   0   0   0   0   0   0    0   0  ...      0     0     0       0   \n",
       "1     0   0   0   0   0   0   0   0    0   0  ...      0     0     0       0   \n",
       "2     0   0   0   0   0   0   0   0    0   0  ...      0     0     0       0   \n",
       "3     0   0   0   0   0   0   0   0    0   0  ...      0     0     0       0   \n",
       "4     0   0   0   0   0   0   0   0    0   0  ...      0     0     0       0   \n",
       "..   ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ...    ...   ...   ...     ...   \n",
       "943   0   0   0   0   0   0   0   0    0   0  ...      0     0     0       0   \n",
       "944   0   0   0   0   0   0   0   0    0   0  ...      0     0     0       0   \n",
       "945   0   0   0   0   0   0   0   0    0   0  ...      0     1     0       0   \n",
       "946   0   0   0   0   0   0   0   0    0   0  ...      0     0     0       0   \n",
       "947   0   0   0   0   0   0   0   0    0   0  ...      0     0     0       0   \n",
       "\n",
       "     yellow_tripdata_2021  yes  yml  youtube  zip  zoomcamp  \n",
       "0                       0    0    0        0    0         0  \n",
       "1                       0    0    0        0    0         1  \n",
       "2                       0    1    0        0    0         0  \n",
       "3                       0    0    0        0    0         0  \n",
       "4                       0    0    0        0    0         0  \n",
       "..                    ...  ...  ...      ...  ...       ...  \n",
       "943                     0    0    1        0    0         0  \n",
       "944                     0    0    0        0    0         0  \n",
       "945                     0    0    0        0    0         0  \n",
       "946                     0    0    0        0    0         0  \n",
       "947                     0    0    0        0    0         1  \n",
       "\n",
       "[948 rows x 1333 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_docs.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5339c0af-68bd-4341-bc01-3ab2a5460c7e",
   "metadata": {},
   "source": [
    "### Using Tfidf from sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683dd15e-ffe9-423f-9aa2-1fdbe65195cf",
   "metadata": {},
   "source": [
    "Another way to create a document matrix is using a Tfidf vectorizer, instead of Count vectorizer. This is going to be an improvement, because instead of just assigning 0 or 1, this vectorizer assignes a float value between 0 and 1. Therefore, we get more information about the significance of the word in the document, rather than just knowing if it is there or not. \n",
    "\n",
    "TF-IDF stands for Term Frequency-Inverse Document Frequency, where:\n",
    "- Term Frequency (TF): The number of times a term appears in a document.\n",
    "- Inverse Document Frequency (IDF): A measure of how much information the word provides, i.e., if it is common or rare across all documents.\n",
    "\n",
    "The score represents the importance of a word in a particular document, relative to all the documents. So, if a word is more rare, it will get a higher score, since that word would carry more meaningful information about the content of that particular document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1964a042-2905-44b3-a25d-ee402dccc2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>y_val</th>\n",
       "      <th>yaml</th>\n",
       "      <th>year</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yellow_tripdata_2021</th>\n",
       "      <th>yes</th>\n",
       "      <th>yml</th>\n",
       "      <th>youtube</th>\n",
       "      <th>zip</th>\n",
       "      <th>zoomcamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.279891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167274</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>948 rows × 1333 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      01   02   03   04   05   06   09   10  100   11  ...  y_val      yaml  \\\n",
       "0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.000000   \n",
       "1    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.000000   \n",
       "2    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.000000   \n",
       "3    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.000000   \n",
       "4    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.000000   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...       ...   \n",
       "943  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.000000   \n",
       "944  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.000000   \n",
       "945  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.167274   \n",
       "946  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.000000   \n",
       "947  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.000000   \n",
       "\n",
       "     year  yellow  yellow_tripdata_2021       yes       yml  youtube  zip  \\\n",
       "0     0.0     0.0                   0.0  0.000000  0.000000      0.0  0.0   \n",
       "1     0.0     0.0                   0.0  0.000000  0.000000      0.0  0.0   \n",
       "2     0.0     0.0                   0.0  0.279891  0.000000      0.0  0.0   \n",
       "3     0.0     0.0                   0.0  0.000000  0.000000      0.0  0.0   \n",
       "4     0.0     0.0                   0.0  0.000000  0.000000      0.0  0.0   \n",
       "..    ...     ...                   ...       ...       ...      ...  ...   \n",
       "943   0.0     0.0                   0.0  0.000000  0.107298      0.0  0.0   \n",
       "944   0.0     0.0                   0.0  0.000000  0.000000      0.0  0.0   \n",
       "945   0.0     0.0                   0.0  0.000000  0.000000      0.0  0.0   \n",
       "946   0.0     0.0                   0.0  0.000000  0.000000      0.0  0.0   \n",
       "947   0.0     0.0                   0.0  0.000000  0.000000      0.0  0.0   \n",
       "\n",
       "     zoomcamp  \n",
       "0    0.000000  \n",
       "1    0.428961  \n",
       "2    0.000000  \n",
       "3    0.000000  \n",
       "4    0.000000  \n",
       "..        ...  \n",
       "943  0.000000  \n",
       "944  0.000000  \n",
       "945  0.000000  \n",
       "946  0.000000  \n",
       "947  0.148428  \n",
       "\n",
       "[948 rows x 1333 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Tfidf gives more importance to less frequent terms\n",
    "\n",
    "tf = TfidfVectorizer(stop_words='english', min_df=5)\n",
    "X = tf.fit_transform(df.text)\n",
    "names = tf.get_feature_names_out()\n",
    "df_docs = pd.DataFrame(X.toarray(), columns=names).T\n",
    "df_docs.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cf0842-acf0-4073-80d5-81317cc6e3ac",
   "metadata": {},
   "source": [
    "Now that we have our document matrix, we can vectorize a query to an array, and then multiply the array with the matrix to determine which document has the most similarity with the query.  \n",
    "\n",
    "For example, for document in row 945:\n",
    "\n",
    "- The score for the word 'yaml' in our dictionary maxtrix is 0.1673, while the score for the word 'year' was 0.\n",
    "- If our query will contain the word 'yaml', then the score for this word will be high, since it is a more rare word. If our query will contain the word 'year', it will not point to this document.\n",
    "-  If we multiply two non-zero values, we get a non-zero value. This means that the similarity score is high, meaning document in row 945 is relevant to the query.\n",
    "\n",
    "What is important to recognize is that we are taking the dot product of these two matrices (the dictionary matrix by the transoformed query matrix), which is also the same as cosine similarity. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3899260f-8815-46be-b0ed-156a1c77695a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1333)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"I just discovered the course, is it too late to join?\"\n",
    "\n",
    "q = tf.transform([query])\n",
    "q.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a3d7d1ba-6284-4709-be0a-2e985c6cc726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49695797492447685\n"
     ]
    }
   ],
   "source": [
    "query_dict = dict(zip(names, q.toarray()[0]))\n",
    "print(query_dict['course'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0adb5ce-5e2e-4f5e-8e16-3c543567dc70",
   "metadata": {},
   "source": [
    "### Taking the dot product to get a similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d39d93fa-c025-420f-9b55-372bc844f53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "score = cosine_similarity(X, q).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3181271b-5daa-45c4-bb3f-fe26b8c5d2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48049682, 0.        , 0.        , 0.2083882 , 0.        ,\n",
       "       0.        , 0.        , 0.17557272, 0.        , 0.        ,\n",
       "       0.        , 0.15870689, 0.        , 0.        , 0.        ,\n",
       "       0.09680922, 0.        , 0.        , 0.07529201, 0.        ,\n",
       "       0.        , 0.        , 0.29986763, 0.10520675, 0.        ,\n",
       "       0.        , 0.        , 0.27447476, 0.12828407, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.05163407, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.03156309,\n",
       "       0.04914818, 0.07138962, 0.        , 0.04329773, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.02804374, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.06739038, 0.        , 0.00980845,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05820102,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.05020173, 0.        , 0.        , 0.0605701 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.05101782, 0.        ,\n",
       "       0.        , 0.04327901, 0.        , 0.03089898, 0.        ,\n",
       "       0.        , 0.05106564, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.08232505, 0.        , 0.        , 0.        , 0.02129978,\n",
       "       0.        , 0.0308046 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.16499001, 0.        ,\n",
       "       0.        , 0.        , 0.03561953, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07733187, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.12621053, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.01502752, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.05398514, 0.        , 0.05115414, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.03869534, 0.04112908, 0.03728758,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.09064943, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.04233182,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07784175, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.02591152, 0.        , 0.03451997, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.04143129, 0.        , 0.05407899, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.22471032, 0.04931254, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.03820044, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.02533066, 0.04085302, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07593909, 0.0723982 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.01328652, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.10202387, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.038628  , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.12084703, 0.10694586, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.08997023, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.05839441, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.12589674, 0.196371  , 0.        , 0.        , 0.06058604,\n",
       "       0.35656584, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.16267179, 0.        , 0.        , 0.30485152, 0.33773583,\n",
       "       0.1231099 , 0.13606474, 0.26771296, 0.        , 0.10835741,\n",
       "       0.13944604, 0.03865125, 0.18083089, 0.03179529, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05501329,\n",
       "       0.03482028, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.06558528, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.03200722, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.05236864, 0.0581809 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.10647026, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.03710508, 0.        , 0.        ,\n",
       "       0.04720167, 0.        , 0.        , 0.04364401, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.03714607, 0.        , 0.        ,\n",
       "       0.        , 0.04808267, 0.        , 0.        , 0.        ,\n",
       "       0.14400322, 0.        , 0.        , 0.03667548, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.06555259, 0.13437698, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.05902352, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.01885244, 0.03485812,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05249485,\n",
       "       0.        , 0.        , 0.        , 0.06591061, 0.        ,\n",
       "       0.        , 0.05969678, 0.        , 0.        , 0.        ,\n",
       "       0.0284637 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.06244092,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.02243907, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15333692,\n",
       "       0.        , 0.03506481, 0.18859024, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.03423508,\n",
       "       0.        , 0.        , 0.01588394, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.04924389, 0.        , 0.        , 0.        ,\n",
       "       0.05098356, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03294308, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.03026252, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.02958017, 0.        , 0.        , 0.        , 0.07023608,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.04109976, 0.        , 0.        , 0.        , 0.04644028,\n",
       "       0.        , 0.        , 0.03833017, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.0364746 , 0.08415092, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.02442063,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.12810532, 0.05637395,\n",
       "       0.04826177, 0.        , 0.04906345, 0.        , 0.26727441,\n",
       "       0.        , 0.        , 0.        , 0.11135001, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.06894246,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.0685693 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04106944, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.06551955,\n",
       "       0.        , 0.07186382, 0.        , 0.        , 0.        ,\n",
       "       0.06333884, 0.        , 0.        , 0.        , 0.12685281,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07782842, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.02660461, 0.06140912, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.05395122, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.02053581, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.02983282, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.03416571, 0.03748537, 0.        , 0.05747492, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.13556595, 0.        ,\n",
       "       0.10025904, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.03278609, 0.11688021, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.03662924, 0.0451592 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1ee0dd27-50d9-4165-8c18-2f17728c1fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 22, 448, 449, 440,   0])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "idx = np.argsort(score)[-5:] # sorts from lowest to highest, so we need the last ones\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2eee37f0-5659-4b29-b822-5404db1cc18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: I just discovered the course, is it too late to join?\n",
      "\n",
      "Search Results:\n",
      "Index 22\n",
      "It's up to you which platform and environment you use for the course.\n",
      "Github codespaces or GCP VM are just possible options, but you can do the entire course from your laptop.\n",
      "\n",
      "\n",
      "Index 448\n",
      "Here’s how you join a in Slack: https://slack.com/help/articles/205239967-Join-a-channel\n",
      "Click “All channels” at the top of your left sidebar. If you don't see this option, click “More” to find it.\n",
      "Browse the list of public channels in your workspace, or use the search bar to search by channel name or description.\n",
      "Select a channel from the list to view it.\n",
      "Click Join Channel.\n",
      "Do we need to provide the GitHub link to only our code corresponding to the homework questions?\n",
      "Yes. You are required to provide the URL to your repo in order to receive a grade\n",
      "\n",
      "\n",
      "Index 449\n",
      "Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\n",
      "In order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.\n",
      "\n",
      "\n",
      "Index 440\n",
      "The process is automated now, so you should receive the email eventually. If you haven’t, check your promotions tab in Gmail as well as spam.\n",
      "If you unsubscribed from our newsletter, you won't get course related updates too.\n",
      "But don't worry, it’s not a problem. To make sure you don’t miss anything, join the #course-ml-zoomcamp channel in Slack and our telegram channel with announcements. This is enough to follow the course.\n",
      "\n",
      "\n",
      "Index 0\n",
      "The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Query: {query}\\n')\n",
    "print('Search Results:')\n",
    "for row in idx:\n",
    "    print(f'Index {row}')\n",
    "    print(df.iloc[row].text)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ba1bc9-c195-4f50-92b2-6f020a4f6f9e",
   "metadata": {},
   "source": [
    "## Taking into account all fields in documents\n",
    "\n",
    "Up to now we have only been using the 'text' field of the documents, but it makes more sense to use the 'question' field. We will take into consideration all the fields, especially the 'question' field, using a boost dictionary. In addition, we can add a filter to only show results relevant to a particular course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "978b6f78-9c51-41cc-87e8-cf90ea87de13",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df)\n",
    "score = np.zeros(n)\n",
    "fields = ['section', 'question', 'text']\n",
    "\n",
    "# giving 'question' 3x more value, and 'text' 0.5 less value.\n",
    "boosts = {\n",
    "    'question': 3,\n",
    "    'text': 0.5\n",
    "}\n",
    "\n",
    "filters = {\n",
    "    'course': 'data-engineering-zoomcamp'\n",
    "}\n",
    "\n",
    "for f in fields:\n",
    "    tf = TfidfVectorizer(stop_words='english', min_df=5)\n",
    "    X = tf.fit_transform(df[f])\n",
    "    q = tf.transform([query])\n",
    "    f_score = cosine_similarity(X, q).flatten()\n",
    "    boost = boosts.get(f, 1.0) # if f not in boosts, assign 1\n",
    "    score += boost*f_score \n",
    "\n",
    "score_no_filter = score.copy()\n",
    "\n",
    "for field, value in filters.items():\n",
    "    mask = (df[field] == value).astype(int).values\n",
    "    score *= mask\n",
    "\n",
    "score_with_filter = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0b919a75-f045-416a-aafc-63322c0d214a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>section</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>I’m new to Slack and can’t find the course cha...</td>\n",
       "      <td>Here’s how you join a in Slack: https://slack....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - Can I follow the course after it fini...</td>\n",
       "      <td>Yes, we will keep all the materials after the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - Which playlist on YouTube should I re...</td>\n",
       "      <td>All the main videos are stored in the Main “DA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - What are the prerequisites for this c...</td>\n",
       "      <td>GitHub - DataTalksClub data-engineering-zoomca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>What are the deadlines in this course?</td>\n",
       "      <td>For the 2023 cohort, you can see the deadlines...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        course                           section  \\\n",
       "448  machine-learning-zoomcamp  General course-related questions   \n",
       "7    data-engineering-zoomcamp  General course-related questions   \n",
       "9    data-engineering-zoomcamp  General course-related questions   \n",
       "1    data-engineering-zoomcamp  General course-related questions   \n",
       "453  machine-learning-zoomcamp  General course-related questions   \n",
       "\n",
       "                                              question  \\\n",
       "448  I’m new to Slack and can’t find the course cha...   \n",
       "7    Course - Can I follow the course after it fini...   \n",
       "9    Course - Which playlist on YouTube should I re...   \n",
       "1    Course - What are the prerequisites for this c...   \n",
       "453             What are the deadlines in this course?   \n",
       "\n",
       "                                                  text  \n",
       "448  Here’s how you join a in Slack: https://slack....  \n",
       "7    Yes, we will keep all the materials after the ...  \n",
       "9    All the main videos are stored in the Main “DA...  \n",
       "1    GitHub - DataTalksClub data-engineering-zoomca...  \n",
       "453  For the 2023 cohort, you can see the deadlines...  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 5 results with no filter yields results in 2 different courses\n",
    "idx = np.argsort(-score_no_filter)[:5]\n",
    "df.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4775dc57-f867-4525-bacd-78f3e4c330cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>section</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - Can I follow the course after it fini...</td>\n",
       "      <td>Yes, we will keep all the materials after the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - What are the prerequisites for this c...</td>\n",
       "      <td>GitHub - DataTalksClub data-engineering-zoomca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - What can I do before the course starts?</td>\n",
       "      <td>You can start by installing and setting up all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - how many Zoomcamps in a year?</td>\n",
       "      <td>There are 3 Zoom Camps in a year, as of 2024. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>How can we contribute to the course?</td>\n",
       "      <td>Star the repo! Share it with friends if you fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       course                           section  \\\n",
       "7   data-engineering-zoomcamp  General course-related questions   \n",
       "1   data-engineering-zoomcamp  General course-related questions   \n",
       "4   data-engineering-zoomcamp  General course-related questions   \n",
       "5   data-engineering-zoomcamp  General course-related questions   \n",
       "34  data-engineering-zoomcamp  General course-related questions   \n",
       "\n",
       "                                             question  \\\n",
       "7   Course - Can I follow the course after it fini...   \n",
       "1   Course - What are the prerequisites for this c...   \n",
       "4    Course - What can I do before the course starts?   \n",
       "5              Course - how many Zoomcamps in a year?   \n",
       "34               How can we contribute to the course?   \n",
       "\n",
       "                                                 text  \n",
       "7   Yes, we will keep all the materials after the ...  \n",
       "1   GitHub - DataTalksClub data-engineering-zoomca...  \n",
       "4   You can start by installing and setting up all...  \n",
       "5   There are 3 Zoom Camps in a year, as of 2024. ...  \n",
       "34  Star the repo! Share it with friends if you fi...  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 5 results with a filter yields results in only one course\n",
    "idx = np.argsort(-score_with_filter)[:5]\n",
    "df.iloc[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d29d44-6478-4dee-911e-f38ca0c54336",
   "metadata": {},
   "source": [
    "## Putting it all together using OOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "72f84e5c-c7b8-4c2f-87e1-6214886285ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "class TextSearch:\n",
    "\n",
    "    def __init__(self, text_fields):\n",
    "        self.text_fields = text_fields\n",
    "        self.matrices = {}\n",
    "        self.vectorizers = {}\n",
    "\n",
    "    def fit(self, records, vectorizer_params={}):\n",
    "        self.df = pd.DataFrame(records)\n",
    "\n",
    "        for f in self.text_fields:\n",
    "            tf = TfidfVectorizer(**vectorizer_params)\n",
    "            X = tf.fit_transform(self.df[f])\n",
    "            self.matrices[f] = X\n",
    "            self.vectorizers[f] = tf\n",
    "\n",
    "    def search(self, query, n_results=10, boost={}, filters={}):\n",
    "        score = np.zeros(len(self.df))\n",
    "\n",
    "        for f in self.text_fields:\n",
    "            b = boost.get(f, 1.0)\n",
    "            q = self.vectorizers[f].transform([query])\n",
    "            s = cosine_similarity(self.matrices[f], q).flatten()\n",
    "            score = score + b * s\n",
    "\n",
    "        for field, value in filters.items():\n",
    "            mask = (self.df[field] == value).values\n",
    "            score = score * mask\n",
    "\n",
    "        idx = np.argsort(-score)[:n_results]\n",
    "        results = self.df.iloc[idx]\n",
    "        return results.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "60c14cf8-21ec-47bb-9037-3644c3bbaf73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I still join the course after the start date?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - When will the course start?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I follow the course after it finishes?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'No, late submissions are not allowed. But if the form is still not closed and it’s after the due date, you can still submit the homework. confirm your submission by the date-timestamp on the Course page.y\\nOlder news:[source1] [source2]',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Homework - Are late submissions of homework allowed?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - What can I do before the course starts?',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example:\n",
    "\n",
    "index = TextSearch(\n",
    "    text_fields=['section', 'question', 'text']\n",
    ")\n",
    "index.fit(documents)\n",
    "\n",
    "index.search(\n",
    "    query='I just singned up. Is it too late to join the course?',\n",
    "    n_results=5,\n",
    "    boost={'question': 3.0},\n",
    "    filters={'course': 'data-engineering-zoomcamp'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a098f73c-25c3-4762-966e-6ab0d0b24d4f",
   "metadata": {},
   "source": [
    "# Semantic/Vector Search\n",
    "\n",
    "As mentioned before, the main limitation of text search is that it relies on the presence of a word in order to determine which documents are relevant. However, often the query can be phrased differently, not contain the exact words in the document, but still be relevant. The magic of using an embedder is that it creates n clusters of similar words/concepts. How does it manage to do this without considering word order?\n",
    "\n",
    "Example:\n",
    "\n",
    "Doc1: \"I am taking a course on machine learning.\"\n",
    "\n",
    "Doc2: \"This program teaches machine learning and data science.\"\n",
    "\n",
    "In these documents, the word 'course' and 'program' both appear with words like 'machine' and 'learning', so it understands that they have similar usage contexts since they appear with a similar set of words. Therefore, it can put 'course' and 'program' in a cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cced01-22e2-4268-ab88-df11ced51768",
   "metadata": {},
   "source": [
    "### Using SVD for vector search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fee059c4-fbfd-4ae4-98bc-3bfb44af5702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "tf = TfidfVectorizer(stop_words='english', min_df=5)\n",
    "svd = TruncatedSVD(n_components=16)\n",
    "\n",
    "X = tf.fit_transform(df['text'])\n",
    "X_emb = svd.fit_transform(X)\n",
    "\n",
    "query = 'I just signed up. Is it too late to join the course?'\n",
    "Q = tf.transform([query])\n",
    "Q_emb = svd.transform(Q)\n",
    "score = cosine_similarity(X_emb, Q_emb).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1129dea5-b2d8-447c-aeab-2ba56d50d18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(948, 16)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3a864bfd-0395-44b6-86ec-8f038bd0dfe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0965294 , -0.08209022, -0.10243038, -0.07913662,  0.06815341,\n",
       "       -0.06097549,  0.02942991, -0.14643791,  0.24885705,  0.27039071,\n",
       "        0.07383093,  0.06997887,  0.07140326,  0.09644724, -0.02853453,\n",
       "        0.00932135])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_emb[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e253a387-fd34-4268-aec8-54ab72d60d97",
   "metadata": {},
   "source": [
    "Instead of a sparse matrix with 1333 dimensions, we have a dense representaiton called an 'embedding' with only 16 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "68b43416-9909-440a-8c79-52a497e4dea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 16)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a3514d35-c651-4e28-8486-a90a6e0d3cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05790344, -0.03847635, -0.05661956, -0.02763634,  0.04012041,\n",
       "        -0.06361821,  0.0182229 , -0.09670466,  0.16579205,  0.17604985,\n",
       "         0.06023559,  0.06394687,  0.05172968,  0.07648963, -0.00458787,\n",
       "         0.014149  ]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8b95b0f5-3802-4236-9263-1cecf696bf3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>section</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Can I submit the homework after the due date?</td>\n",
       "      <td>No, it’s not possible. The form is closed afte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>Projects (Midterm and Capstone)</td>\n",
       "      <td>What If I submitted only two projects and fail...</td>\n",
       "      <td>If you have submitted two projects (and peer-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - When will the course start?</td>\n",
       "      <td>The purpose of this document is to capture fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - Can I still join the course after the...</td>\n",
       "      <td>Yes, even if you don't register, you're still ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Is it going to be live? When?</td>\n",
       "      <td>The course videos are pre-recorded, you can st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        course                           section  \\\n",
       "451  machine-learning-zoomcamp  General course-related questions   \n",
       "764  machine-learning-zoomcamp   Projects (Midterm and Capstone)   \n",
       "0    data-engineering-zoomcamp  General course-related questions   \n",
       "2    data-engineering-zoomcamp  General course-related questions   \n",
       "436  machine-learning-zoomcamp  General course-related questions   \n",
       "\n",
       "                                              question  \\\n",
       "451      Can I submit the homework after the due date?   \n",
       "764  What If I submitted only two projects and fail...   \n",
       "0                 Course - When will the course start?   \n",
       "2    Course - Can I still join the course after the...   \n",
       "436                      Is it going to be live? When?   \n",
       "\n",
       "                                                  text  \n",
       "451  No, it’s not possible. The form is closed afte...  \n",
       "764  If you have submitted two projects (and peer-r...  \n",
       "0    The purpose of this document is to capture fre...  \n",
       "2    Yes, even if you don't register, you're still ...  \n",
       "436  The course videos are pre-recorded, you can st...  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = cosine_similarity(X_emb, Q_emb).flatten()\n",
    "idx = np.argsort(-score)[:5]\n",
    "df.loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "79200bcb-4d3c-4071-ab81-f99500a63263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>section</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - I have registered for the Data Engine...</td>\n",
       "      <td>You don't need it. You're accepted. You can al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - Can I get support if I take the cours...</td>\n",
       "      <td>Yes, the slack channel remains open and you ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>I may end up submitting the assignment late. W...</td>\n",
       "      <td>Depends on whether the form will still be open...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>I filled the form, but haven't received a conf...</td>\n",
       "      <td>The process is automated now, so you should re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Can I submit the homework after the due date?</td>\n",
       "      <td>No, it’s not possible. The form is closed afte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        course                           section  \\\n",
       "3    data-engineering-zoomcamp  General course-related questions   \n",
       "8    data-engineering-zoomcamp  General course-related questions   \n",
       "797  machine-learning-zoomcamp                     Miscellaneous   \n",
       "440  machine-learning-zoomcamp  General course-related questions   \n",
       "451  machine-learning-zoomcamp  General course-related questions   \n",
       "\n",
       "                                              question  \\\n",
       "3    Course - I have registered for the Data Engine...   \n",
       "8    Course - Can I get support if I take the cours...   \n",
       "797  I may end up submitting the assignment late. W...   \n",
       "440  I filled the form, but haven't received a conf...   \n",
       "451      Can I submit the homework after the due date?   \n",
       "\n",
       "                                                  text  \n",
       "3    You don't need it. You're accepted. You can al...  \n",
       "8    Yes, the slack channel remains open and you ca...  \n",
       "797  Depends on whether the form will still be open...  \n",
       "440  The process is automated now, so you should re...  \n",
       "451  No, it’s not possible. The form is closed afte...  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'I just enrolled. Is it too late to join the program?'\n",
    "Q = tf.transform([query])\n",
    "Q_emb = svd.transform(Q)\n",
    "score = cosine_similarity(X_emb, Q_emb).flatten()\n",
    "idx = np.argsort(-score)[:5]\n",
    "df.loc[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd3bab3-3006-46c9-9346-8266fe63a945",
   "metadata": {},
   "source": [
    "### Using NMF for vector search\n",
    "\n",
    "NMF (Non-negative Matrix Factorization) is considered to be more interpretable than SVD since the matrix values are all positive, and because it leads to sparser matrices. Since a matrix value represents 'how much' of that cluster is related, a negative value can lack meaning and be more confusing. In addition, a sparse matrix indicates clearly which of the clusters are playing a part. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6b3d65b2-6d56-43e0-9f72-ae81a1d582cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00613327, 0.00589399, 0.        , 0.        , 0.08526761,\n",
       "       0.        , 0.0010501 , 0.        , 0.00216954, 0.01244853,\n",
       "       0.00030579, 0.        , 0.        , 0.00766827, 0.00452049,\n",
       "       0.00914782])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "nmf = NMF(n_components=16)\n",
    "X_emb = nmf.fit_transform(X)\n",
    "X_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "735a2794-ef35-4d1f-8087-d5c66d281d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMF creates 'clusters' of different topics, and non zero values can be seen as the query being related to those 2 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a9d9c44b-e9ee-46cc-840c-58d54b6a53c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.44931879e-02, 1.39271127e-02, 0.00000000e+00, 8.27306250e-03,\n",
       "       7.75442915e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       4.34842512e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 2.11862938e-02, 2.28288798e-02, 0.00000000e+00])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'I just signed up. Is it too late to join the course?'\n",
    "Q = cv.transform([query])\n",
    "Q_emb = nmf.transform(Q)\n",
    "Q_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d66693e1-3c31-4053-a7a5-8f4a8a17606a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>section</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Submitting learning in public links</td>\n",
       "      <td>When you post about what you learned from the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>I just joined. What should I do next? How can ...</td>\n",
       "      <td>Welcome to the course! Go to the course page (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - When will the course start?</td>\n",
       "      <td>The purpose of this document is to capture fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>Projects (Midterm and Capstone)</td>\n",
       "      <td>What modules, topics, problem-sets should a mi...</td>\n",
       "      <td>Answer: Ideally midterms up to module-06, caps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>Projects (Midterm and Capstone)</td>\n",
       "      <td>How to conduct peer reviews for projects?</td>\n",
       "      <td>Answer: Previous cohorts projects page has ins...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        course                           section  \\\n",
       "456  machine-learning-zoomcamp  General course-related questions   \n",
       "452  machine-learning-zoomcamp  General course-related questions   \n",
       "0    data-engineering-zoomcamp  General course-related questions   \n",
       "758  machine-learning-zoomcamp   Projects (Midterm and Capstone)   \n",
       "760  machine-learning-zoomcamp   Projects (Midterm and Capstone)   \n",
       "\n",
       "                                              question  \\\n",
       "456                Submitting learning in public links   \n",
       "452  I just joined. What should I do next? How can ...   \n",
       "0                 Course - When will the course start?   \n",
       "758  What modules, topics, problem-sets should a mi...   \n",
       "760          How to conduct peer reviews for projects?   \n",
       "\n",
       "                                                  text  \n",
       "456  When you post about what you learned from the ...  \n",
       "452  Welcome to the course! Go to the course page (...  \n",
       "0    The purpose of this document is to capture fre...  \n",
       "758  Answer: Ideally midterms up to module-06, caps...  \n",
       "760  Answer: Previous cohorts projects page has ins...  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = cosine_similarity(X_emb, Q_emb).flatten()\n",
    "idx = np.argsort(-score)[:5]\n",
    "df.loc[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "614f8283-5e0a-4542-9692-676a72371d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorSearch:\n",
    "\n",
    "    def __init__(self, text_fields):\n",
    "        self.text_fields = text_fields\n",
    "        self.matrices = {}\n",
    "        self.vectorizers = {}\n",
    "        self.embedders = {}\n",
    "\n",
    "    def fit(self, records, vectorizer_params={}):\n",
    "        self.df = pd.DataFrame(records)\n",
    "\n",
    "        for f in self.text_fields:\n",
    "            tf = TfidfVectorizer(**vectorizer_params)\n",
    "            X = tf.fit_transform(self.df[f])\n",
    "            self.vectorizers[f] = tf\n",
    "\n",
    "            svd = TruncatedSVD(n_components=16)\n",
    "            X_emb = svd.fit_transform(X)\n",
    "            self.matrices[f] = X_emb\n",
    "            self.embedders[f] = svd\n",
    "\n",
    "    def search(self, query, n_results=10, boost={}, filters={}):\n",
    "        score = np.zeros(len(self.df))\n",
    "    \n",
    "        for f in self.text_fields:\n",
    "            b = boost.get(f, 1.0)\n",
    "            q = self.vectorizers[f].transform([query])\n",
    "            q_emb = self.embedders[f].transform(q)\n",
    "            s = cosine_similarity(self.matrices[f], q_emb).flatten()\n",
    "            score = score + b * s\n",
    "    \n",
    "        for field, value in filters.items():\n",
    "            mask = (self.df[field] == value).values\n",
    "            score = score * mask\n",
    "    \n",
    "        idx = np.argsort(-score)[:n_results]\n",
    "        results = self.df.iloc[idx]\n",
    "        return results.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c9c11f96-a3a1-4c19-9af8-98b84350ecab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Yes. For the 2024 edition we are using Mage AI instead of Prefect and re-recorded the terraform videos, For 2023, we used Prefect instead of Airflow..',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Is the current cohort going to be different from the previous cohort?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'Yes! Every “Office Hours” will be recorded and available a few minutes after the live session is over; so you can view (or rewatch) whenever you want.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Office Hours - I can’t attend the “Office hours” / workshop, will it be recorded?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'The zoom link is only published to instructors/presenters/TAs.\\nStudents participate via Youtube Live and submit questions to Slido (link would be pinned in the chat when Alexey goes Live). The video URL should be posted in the announcements channel on Telegram & Slack before it begins. Also, you will see it live on the DataTalksClub YouTube Channel.\\nDon’t post your questions in chat as it would be off-screen before the instructors/moderators have a chance to answer it if the room is very active.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Office Hours - What is the video/zoom link to the stream for the “Office Hour” or workshop sessions?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - When will the course start?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'Yes! Linux is ideal but technically it should not matter. Students last year used all 3 OSes successfully',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Environment - Is the course [Windows/mac/Linux/...] friendly?',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "index = VectorSearch(\n",
    "    text_fields=['section', 'question', 'text']\n",
    ")\n",
    "index.fit(documents)\n",
    "\n",
    "index.search(\n",
    "    query='I just signed up. Is it too late to join the course?',\n",
    "    n_results=5,\n",
    "    boost={'question': 3.0\n",
    "          },\n",
    "    filters={'course': 'data-engineering-zoomcamp'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc0dcd1-1b49-4ba5-a823-6f6d207de843",
   "metadata": {},
   "source": [
    "## BERT\n",
    "NN that turns a document into an embedding. Captures not only semantic similarity but also word order. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "45aa8020-511f-4cbf-9d40-db2872b09b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "# loading tokenizer and pre-trained model\n",
    "# tokenizer turns text into a numerical representation\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "model.eval()  # Set the model to evaluation mode if not training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7e2e84fd-8e6f-4b3b-b181-d70eed14e8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2748,  1010,  2057,  2097,  2562,  2035,  1996,  4475,  2044,\n",
       "          1996,  2607, 12321,  1012,   102],\n",
       "        [  101,  2017,  2064,  3582,  1996,  2607,  2012,  2115,  2219,  6393,\n",
       "          2044,  2009, 12321,   102,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Yes, we will keep all the materials after the course finishes.\",\n",
    "    \"You can follow the course at your own pace after it finishes\"\n",
    "]\n",
    "encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "db32fbc5-c3e7-4752-aca0-01c9be60955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # Disable gradient calculation for inference\n",
    "    outputs = model(**encoded_input)\n",
    "    hidden_states = outputs.last_hidden_state # contains embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "851a9273-febf-480e-bb42-7b3ea5a93cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 15, 768])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states.shape\n",
    "# 2 is num. documens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "03a1803c-d8fb-45e9-965a-867142674f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1010,  0.0181,  0.1303,  ..., -0.2932,  0.1863,  0.6615],\n",
       "        [ 1.0608, -0.1242,  0.1370,  ..., -0.1605,  1.0429,  0.3532],\n",
       "        [ 0.1802,  0.0776,  0.3941,  ..., -0.1379,  0.5974,  0.1704],\n",
       "        ...,\n",
       "        [ 0.4738, -0.0184,  0.2186,  ..., -0.0013, -0.0833, -0.2170],\n",
       "        [ 0.6516,  0.1216, -0.2494,  ...,  0.1557, -0.5632, -0.4310],\n",
       "        [ 0.7164,  0.2157, -0.0281,  ...,  0.2281, -0.6725, -0.3245]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "61fda83c-9c49-47ad-bb4f-9d8b40dc3f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings = hidden_states.mean(dim=1)\n",
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d9e2e7f4-620a-4970-be55-fe74b68506e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3600, -0.1607,  0.3545,  ...,  0.0429,  0.0348, -0.0382],\n",
       "        [ 0.1785, -0.5000,  0.2528,  ..., -0.1141, -0.3361,  0.4110]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "910c1919-b465-40e7-8f35-b9a3dc7e5dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_emb = sentence_embeddings.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5a03e66f-c81b-4db8-aa13-abd7eadbece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batches(seq, n):\n",
    "    result = []\n",
    "    for i in range(0, len(seq), n):\n",
    "        batch = seq[i:i+n]\n",
    "        result.append(batch)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "14fbc4a7-eaa0-4791-946c-e18f8c4e1a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████| 119/119 [11:11<00:00,  5.65s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "texts = df['text'].tolist()\n",
    "text_batches = make_batches(texts, 8)\n",
    "\n",
    "all_embeddings = []\n",
    "\n",
    "for batch in tqdm(text_batches):\n",
    "    encoded_input = tokenizer(batch, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoded_input)\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "        \n",
    "        batch_embeddings = hidden_states.mean(dim=1)\n",
    "        batch_embeddings_np = batch_embeddings.cpu().numpy()\n",
    "        all_embeddings.append(batch_embeddings_np)\n",
    "\n",
    "final_embeddings = np.vstack(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a5da646d-a822-4188-9908-747c27d4b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings(texts, batch_size=8):\n",
    "    text_batches = make_batches(texts, 8)\n",
    "    \n",
    "    all_embeddings = []\n",
    "    \n",
    "    for batch in tqdm(text_batches):\n",
    "        encoded_input = tokenizer(batch, padding=True, truncation=True, return_tensors='pt')\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encoded_input)\n",
    "            hidden_states = outputs.last_hidden_state\n",
    "            \n",
    "            batch_embeddings = hidden_states.mean(dim=1)\n",
    "            batch_embeddings_np = batch_embeddings.cpu().numpy()\n",
    "            all_embeddings.append(batch_embeddings_np)\n",
    "    \n",
    "    final_embeddings = np.vstack(all_embeddings)\n",
    "    return final_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ed2d0701-8e2f-4d62-8a4e-a20f2a9ba0f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_batches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[117], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_text \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[116], line 2\u001b[0m, in \u001b[0;36mcompute_embeddings\u001b[0;34m(texts, batch_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_embeddings\u001b[39m(texts, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     text_batches \u001b[38;5;241m=\u001b[39m \u001b[43mmake_batches\u001b[49m(texts, \u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m      4\u001b[0m     all_embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(text_batches):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'make_batches' is not defined"
     ]
    }
   ],
   "source": [
    "X_text = compute_embeddings(df['text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff42708-f015-4bda-985d-b9aebe3a6d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

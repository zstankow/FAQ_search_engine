{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e34c827-c8b5-443f-a1e1-834f0f1a4d1c",
   "metadata": {},
   "source": [
    "# Creating a simple search engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d870cba3-faa5-45b1-a7a4-3a1ca8fccd29",
   "metadata": {},
   "source": [
    "### Goals of this notebook\n",
    "\n",
    "1) Explore a few different ways we can implement a simple search engine for queries. The goal is that the user can type a query related to the zoomcamp course FAQ pages, and can receive a few results in order of their relevance. We will see how different methods yield different results and which are more effective in extracting the most relevant results. \n",
    "\n",
    "In this exercise we will look at both __Text Search and Semantic/Vector__ search methods. We can illustrate the difference in these methods with a small example:\n",
    "\n",
    "`query = 'I just discovered the course. Can I still join?'`\n",
    "\n",
    "In text search, we will find all the documents that contain words like 'discovered', 'course', 'join', etc. However, often the user forms a question that does not really match the documents. For example:\n",
    "\n",
    "`query = 'I just found out about the program. Can I still enroll?'`\n",
    "\n",
    "Semantically, both queries have the same meaning, but with text search we will not get good results. This is when a semantic/vector approach will perform much better. \n",
    "\n",
    "2) Understand the steps of getting relevant search results using more basic methods like CountVectorizer/TfidfVectorizer (Bag of Words methods), then slightly more sophisticated methods using singular value reduction (dimensionality reduction methods) like SVD and NMF to embed the vector, and finally using a pretrained NN called BERT for best results.\n",
    "\n",
    "Here is a quick breakdown of each of these methods:\n",
    "\n",
    "__Bag of Words (text search) method__:\n",
    "- create an instance of the Vectorizer (CV, Tfdif), fit_transform the documents to get document matrix (X), and transform the query (q)\n",
    "- calculate similarity score (with cosine similarity between X and q) and rank results\n",
    "\n",
    "__Semantic/Vector methods__:\n",
    "- create an instance of the Vectorizer (CV, Tfdif), fit_transform the documents to get document matrix (X), and transform the query (Q)\n",
    "- create an instance of the Embedder (SVD, NMF), fit_transform X to dense document matrix (X_emb), and transform Q to get dense query array (Q_emb)\n",
    "- calculate similarity score (with cosine similarity between X_emb and Q_emb) and rank results\n",
    "\n",
    "__Pre-trained BERT method__:\n",
    "- Load BERT tokenizer and model\n",
    "- Embed the text\n",
    "\n",
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15df5206-059b-4d4a-a35a-f857ab644555",
   "metadata": {},
   "source": [
    "### Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e435a393-7e56-4966-a375-6de0f1c940a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a865da7-a750-4682-bea0-e7b206d76977",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bf55624-b8a7-49c9-a678-dd13d22ba7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - Can I still join the course after the start date?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b4c5be1-1287-40d1-8b8e-4222c4498281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to dataframe\n",
    "df = pd.DataFrame(documents, columns=['course', 'section', 'question', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f5cd729-db88-42d7-ab0d-c0f3d8bd35cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>section</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - When will the course start?</td>\n",
       "      <td>The purpose of this document is to capture fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - What are the prerequisites for this c...</td>\n",
       "      <td>GitHub - DataTalksClub data-engineering-zoomca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - Can I still join the course after the...</td>\n",
       "      <td>Yes, even if you don't register, you're still ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - I have registered for the Data Engine...</td>\n",
       "      <td>You don't need it. You're accepted. You can al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - What can I do before the course starts?</td>\n",
       "      <td>You can start by installing and setting up all...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      course                           section  \\\n",
       "0  data-engineering-zoomcamp  General course-related questions   \n",
       "1  data-engineering-zoomcamp  General course-related questions   \n",
       "2  data-engineering-zoomcamp  General course-related questions   \n",
       "3  data-engineering-zoomcamp  General course-related questions   \n",
       "4  data-engineering-zoomcamp  General course-related questions   \n",
       "\n",
       "                                            question  \\\n",
       "0               Course - When will the course start?   \n",
       "1  Course - What are the prerequisites for this c...   \n",
       "2  Course - Can I still join the course after the...   \n",
       "3  Course - I have registered for the Data Engine...   \n",
       "4   Course - What can I do before the course starts?   \n",
       "\n",
       "                                                text  \n",
       "0  The purpose of this document is to capture fre...  \n",
       "1  GitHub - DataTalksClub data-engineering-zoomca...  \n",
       "2  Yes, even if you don't register, you're still ...  \n",
       "3  You don't need it. You're accepted. You can al...  \n",
       "4  You can start by installing and setting up all...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f296a0a-3604-41cb-a0f3-5f64e6d2dd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(948, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91784a3f-0781-4220-84fd-c5d97c28e286",
   "metadata": {},
   "source": [
    "## Text Search Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b3a36d-4185-4c22-9185-409f701ba3d2",
   "metadata": {},
   "source": [
    "### Using CountVectorizer from sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cabf5f-d38d-4859-99f8-1e2bce5cd1c5",
   "metadata": {},
   "source": [
    "From the dataframe `df` we see that we have 948 documents, each containing 4 different fields. We need to convert the text of each document to a numerical representation (to encode the document), in a process called vectorization. In vectorization, we turn the document into a vector with encodings. We are essentially creating a dictionary of all the words that appear in all our documents, and then assigning 1 or 0 if the document contains this word. This creates a document matrix, when the rows are each document (in our case, 948 rows) and the columns are the words/tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3db6d835-2008-482e-9177-38f143da42e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(stop_words='english', min_df=5) \n",
    "X = cv.fit_transform(df.text)\n",
    "names = cv.get_feature_names_out()\n",
    "df_docs = pd.DataFrame(X.toarray(), columns=names).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ce2c57-b451-48ad-a9b6-afabaeca1806",
   "metadata": {},
   "source": [
    "Notes about parameters in CV instance: \n",
    "\n",
    "__min_df__: only care about terms that appear in 5 documents (to avoid questions that are rarely asked or in nonEglish languages)\n",
    "__stop_words__: Stopwords are the words which occur frequently and don't provide any useful information. We define it as 'english' to recognize and remove all the English stop-words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0912e086-2748-4146-b5f7-75e26ad6285f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['01', '02', '03', ..., 'youtube', 'zip', 'zoomcamp'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cb5266-ec08-4540-a2a4-9b0d35650048",
   "metadata": {},
   "source": [
    "After fitting the `text` feature of the dataframe of documents, we can see our word dictionary using the CountVectorizer.get_feature_names_out(). It contains 1333 words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10751f50-0f77-4a42-a95c-ce143461675e",
   "metadata": {},
   "source": [
    "Our document matrix after using CountVectorizer:\n",
    "\n",
    "We can see that it is a sparse matrix, meaning that most of the values are 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed0b4982-cb7f-413a-a9cf-c2587f32395d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>y_val</th>\n",
       "      <th>yaml</th>\n",
       "      <th>year</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yellow_tripdata_2021</th>\n",
       "      <th>yes</th>\n",
       "      <th>yml</th>\n",
       "      <th>youtube</th>\n",
       "      <th>zip</th>\n",
       "      <th>zoomcamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>948 rows × 1333 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     01  02  03  04  05  06  09  10  100  11  ...  y_val  yaml  year  yellow  \\\n",
       "0     0   0   0   0   0   0   0   0    0   0  ...      0     0     0       0   \n",
       "1     0   0   0   0   0   0   0   0    0   0  ...      0     0     0       0   \n",
       "2     0   0   0   0   0   0   0   0    0   0  ...      0     0     0       0   \n",
       "3     0   0   0   0   0   0   0   0    0   0  ...      0     0     0       0   \n",
       "4     0   0   0   0   0   0   0   0    0   0  ...      0     0     0       0   \n",
       "..   ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ...    ...   ...   ...     ...   \n",
       "943   0   0   0   0   0   0   0   0    0   0  ...      0     0     0       0   \n",
       "944   0   0   0   0   0   0   0   0    0   0  ...      0     0     0       0   \n",
       "945   0   0   0   0   0   0   0   0    0   0  ...      0     1     0       0   \n",
       "946   0   0   0   0   0   0   0   0    0   0  ...      0     0     0       0   \n",
       "947   0   0   0   0   0   0   0   0    0   0  ...      0     0     0       0   \n",
       "\n",
       "     yellow_tripdata_2021  yes  yml  youtube  zip  zoomcamp  \n",
       "0                       0    0    0        0    0         0  \n",
       "1                       0    0    0        0    0         1  \n",
       "2                       0    1    0        0    0         0  \n",
       "3                       0    0    0        0    0         0  \n",
       "4                       0    0    0        0    0         0  \n",
       "..                    ...  ...  ...      ...  ...       ...  \n",
       "943                     0    0    1        0    0         0  \n",
       "944                     0    0    0        0    0         0  \n",
       "945                     0    0    0        0    0         0  \n",
       "946                     0    0    0        0    0         0  \n",
       "947                     0    0    0        0    0         1  \n",
       "\n",
       "[948 rows x 1333 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_docs.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5339c0af-68bd-4341-bc01-3ab2a5460c7e",
   "metadata": {},
   "source": [
    "### Using Tfidf from sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683dd15e-ffe9-423f-9aa2-1fdbe65195cf",
   "metadata": {},
   "source": [
    "Another way to create a document matrix is using a Tfidf vectorizer, instead of Count vectorizer. This is going to be an improvement, because instead of just assigning 0 or 1, this vectorizer assignes a float value between 0 and 1. Therefore, we get more information about the significance of the word in the document, rather than just knowing if it is there or not. \n",
    "\n",
    "TF-IDF stands for Term Frequency-Inverse Document Frequency, where:\n",
    "- Term Frequency (TF): The number of times a term appears in a document.\n",
    "- Inverse Document Frequency (IDF): A measure of how much information the word provides, i.e., if it is common or rare across all documents.\n",
    "\n",
    "The score represents the importance of a word in a particular document, relative to all the documents. So, if a word is more rare, it will get a higher score, since that word would carry more meaningful information about the content of that particular document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1964a042-2905-44b3-a25d-ee402dccc2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>y_val</th>\n",
       "      <th>yaml</th>\n",
       "      <th>year</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yellow_tripdata_2021</th>\n",
       "      <th>yes</th>\n",
       "      <th>yml</th>\n",
       "      <th>youtube</th>\n",
       "      <th>zip</th>\n",
       "      <th>zoomcamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.279891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167274</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>948 rows × 1333 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      01   02   03   04   05   06   09   10  100   11  ...  y_val      yaml  \\\n",
       "0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.000000   \n",
       "1    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.000000   \n",
       "2    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.000000   \n",
       "3    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.000000   \n",
       "4    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.000000   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...       ...   \n",
       "943  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.000000   \n",
       "944  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.000000   \n",
       "945  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.167274   \n",
       "946  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.000000   \n",
       "947  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.000000   \n",
       "\n",
       "     year  yellow  yellow_tripdata_2021       yes       yml  youtube  zip  \\\n",
       "0     0.0     0.0                   0.0  0.000000  0.000000      0.0  0.0   \n",
       "1     0.0     0.0                   0.0  0.000000  0.000000      0.0  0.0   \n",
       "2     0.0     0.0                   0.0  0.279891  0.000000      0.0  0.0   \n",
       "3     0.0     0.0                   0.0  0.000000  0.000000      0.0  0.0   \n",
       "4     0.0     0.0                   0.0  0.000000  0.000000      0.0  0.0   \n",
       "..    ...     ...                   ...       ...       ...      ...  ...   \n",
       "943   0.0     0.0                   0.0  0.000000  0.107298      0.0  0.0   \n",
       "944   0.0     0.0                   0.0  0.000000  0.000000      0.0  0.0   \n",
       "945   0.0     0.0                   0.0  0.000000  0.000000      0.0  0.0   \n",
       "946   0.0     0.0                   0.0  0.000000  0.000000      0.0  0.0   \n",
       "947   0.0     0.0                   0.0  0.000000  0.000000      0.0  0.0   \n",
       "\n",
       "     zoomcamp  \n",
       "0    0.000000  \n",
       "1    0.428961  \n",
       "2    0.000000  \n",
       "3    0.000000  \n",
       "4    0.000000  \n",
       "..        ...  \n",
       "943  0.000000  \n",
       "944  0.000000  \n",
       "945  0.000000  \n",
       "946  0.000000  \n",
       "947  0.148428  \n",
       "\n",
       "[948 rows x 1333 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Tfidf gives more importance to less frequent terms\n",
    "\n",
    "tf = TfidfVectorizer(stop_words='english', min_df=5)\n",
    "X = tf.fit_transform(df.text)\n",
    "names = tf.get_feature_names_out()\n",
    "df_docs = pd.DataFrame(X.toarray(), columns=names).T\n",
    "df_docs.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cf0842-acf0-4073-80d5-81317cc6e3ac",
   "metadata": {},
   "source": [
    "Now that we have our document matrix, we can vectorize a query to an array, and then multiply the array with the matrix to determine which document has the most similarity with the query.  \n",
    "\n",
    "For example, for document in row 945:\n",
    "\n",
    "- The score for the word 'yaml' in our dictionary maxtrix is 0.1673, while the score for the word 'year' was 0.\n",
    "- If our query will contain the word 'yaml', then the score for this word will be high, since it is a more rare word. If our query will contain the word 'year', it will not point to this document.\n",
    "-  If we multiply two non-zero values, we get a non-zero value. This means that the similarity score is high, meaning document in row 945 is relevant to the query.\n",
    "\n",
    "What is important to recognize is that we are taking the dot product of these two matrices (the dictionary matrix by the transoformed query matrix), which is also the same as cosine similarity. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3899260f-8815-46be-b0ed-156a1c77695a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1333)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"I just discovered the course, is it too late to join?\"\n",
    "\n",
    "q = tf.transform([query])\n",
    "q.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a3d7d1ba-6284-4709-be0a-2e985c6cc726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49695797492447685\n"
     ]
    }
   ],
   "source": [
    "query_dict = dict(zip(names, q.toarray()[0]))\n",
    "print(query_dict['course'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0adb5ce-5e2e-4f5e-8e16-3c543567dc70",
   "metadata": {},
   "source": [
    "### Taking the dot product to get a similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d39d93fa-c025-420f-9b55-372bc844f53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "score = cosine_similarity(X, q).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3181271b-5daa-45c4-bb3f-fe26b8c5d2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48049682, 0.        , 0.        , 0.2083882 , 0.        ,\n",
       "       0.        , 0.        , 0.17557272, 0.        , 0.        ,\n",
       "       0.        , 0.15870689, 0.        , 0.        , 0.        ,\n",
       "       0.09680922, 0.        , 0.        , 0.07529201, 0.        ,\n",
       "       0.        , 0.        , 0.29986763, 0.10520675, 0.        ,\n",
       "       0.        , 0.        , 0.27447476, 0.12828407, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.05163407, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.03156309,\n",
       "       0.04914818, 0.07138962, 0.        , 0.04329773, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.02804374, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.06739038, 0.        , 0.00980845,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05820102,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.05020173, 0.        , 0.        , 0.0605701 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.05101782, 0.        ,\n",
       "       0.        , 0.04327901, 0.        , 0.03089898, 0.        ,\n",
       "       0.        , 0.05106564, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.08232505, 0.        , 0.        , 0.        , 0.02129978,\n",
       "       0.        , 0.0308046 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.16499001, 0.        ,\n",
       "       0.        , 0.        , 0.03561953, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07733187, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.12621053, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.01502752, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.05398514, 0.        , 0.05115414, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.03869534, 0.04112908, 0.03728758,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.09064943, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.04233182,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07784175, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.02591152, 0.        , 0.03451997, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.04143129, 0.        , 0.05407899, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.22471032, 0.04931254, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.03820044, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.02533066, 0.04085302, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07593909, 0.0723982 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.01328652, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.10202387, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.038628  , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.12084703, 0.10694586, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.08997023, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.05839441, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.12589674, 0.196371  , 0.        , 0.        , 0.06058604,\n",
       "       0.35656584, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.16267179, 0.        , 0.        , 0.30485152, 0.33773583,\n",
       "       0.1231099 , 0.13606474, 0.26771296, 0.        , 0.10835741,\n",
       "       0.13944604, 0.03865125, 0.18083089, 0.03179529, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05501329,\n",
       "       0.03482028, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.06558528, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.03200722, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.05236864, 0.0581809 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.10647026, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.03710508, 0.        , 0.        ,\n",
       "       0.04720167, 0.        , 0.        , 0.04364401, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.03714607, 0.        , 0.        ,\n",
       "       0.        , 0.04808267, 0.        , 0.        , 0.        ,\n",
       "       0.14400322, 0.        , 0.        , 0.03667548, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.06555259, 0.13437698, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.05902352, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.01885244, 0.03485812,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05249485,\n",
       "       0.        , 0.        , 0.        , 0.06591061, 0.        ,\n",
       "       0.        , 0.05969678, 0.        , 0.        , 0.        ,\n",
       "       0.0284637 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.06244092,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.02243907, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15333692,\n",
       "       0.        , 0.03506481, 0.18859024, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.03423508,\n",
       "       0.        , 0.        , 0.01588394, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.04924389, 0.        , 0.        , 0.        ,\n",
       "       0.05098356, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03294308, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.03026252, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.02958017, 0.        , 0.        , 0.        , 0.07023608,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.04109976, 0.        , 0.        , 0.        , 0.04644028,\n",
       "       0.        , 0.        , 0.03833017, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.0364746 , 0.08415092, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.02442063,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.12810532, 0.05637395,\n",
       "       0.04826177, 0.        , 0.04906345, 0.        , 0.26727441,\n",
       "       0.        , 0.        , 0.        , 0.11135001, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.06894246,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.0685693 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04106944, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.06551955,\n",
       "       0.        , 0.07186382, 0.        , 0.        , 0.        ,\n",
       "       0.06333884, 0.        , 0.        , 0.        , 0.12685281,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07782842, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.02660461, 0.06140912, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.05395122, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.02053581, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.02983282, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.03416571, 0.03748537, 0.        , 0.05747492, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.13556595, 0.        ,\n",
       "       0.10025904, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.03278609, 0.11688021, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.03662924, 0.0451592 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1ee0dd27-50d9-4165-8c18-2f17728c1fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 22, 448, 449, 440,   0])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "idx = np.argsort(score)[-5:] # sorts from lowest to highest, so we need the last ones\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2eee37f0-5659-4b29-b822-5404db1cc18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: I just discovered the course, is it too late to join?\n",
      "\n",
      "Search Results:\n",
      "Index 22\n",
      "It's up to you which platform and environment you use for the course.\n",
      "Github codespaces or GCP VM are just possible options, but you can do the entire course from your laptop.\n",
      "\n",
      "\n",
      "Index 448\n",
      "Here’s how you join a in Slack: https://slack.com/help/articles/205239967-Join-a-channel\n",
      "Click “All channels” at the top of your left sidebar. If you don't see this option, click “More” to find it.\n",
      "Browse the list of public channels in your workspace, or use the search bar to search by channel name or description.\n",
      "Select a channel from the list to view it.\n",
      "Click Join Channel.\n",
      "Do we need to provide the GitHub link to only our code corresponding to the homework questions?\n",
      "Yes. You are required to provide the URL to your repo in order to receive a grade\n",
      "\n",
      "\n",
      "Index 449\n",
      "Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\n",
      "In order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.\n",
      "\n",
      "\n",
      "Index 440\n",
      "The process is automated now, so you should receive the email eventually. If you haven’t, check your promotions tab in Gmail as well as spam.\n",
      "If you unsubscribed from our newsletter, you won't get course related updates too.\n",
      "But don't worry, it’s not a problem. To make sure you don’t miss anything, join the #course-ml-zoomcamp channel in Slack and our telegram channel with announcements. This is enough to follow the course.\n",
      "\n",
      "\n",
      "Index 0\n",
      "The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Query: {query}\\n')\n",
    "print('Search Results:')\n",
    "for row in idx:\n",
    "    print(f'Index {row}')\n",
    "    print(df.iloc[row].text)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ba1bc9-c195-4f50-92b2-6f020a4f6f9e",
   "metadata": {},
   "source": [
    "## Taking into account all fields in documents\n",
    "\n",
    "Up to now we have only been using the 'text' field of the documents, but it makes more sense to use the 'question' field. We will take into consideration all the fields, especially the 'question' field, using a boost dictionary. In addition, we can add a filter to only show results relevant to a particular course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "978b6f78-9c51-41cc-87e8-cf90ea87de13",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df)\n",
    "score = np.zeros(n)\n",
    "fields = ['section', 'question', 'text']\n",
    "\n",
    "# giving 'question' 3x more value, and 'text' 0.5 less value.\n",
    "boosts = {\n",
    "    'question': 3,\n",
    "    'text': 0.5\n",
    "}\n",
    "\n",
    "filters = {\n",
    "    'course': 'data-engineering-zoomcamp'\n",
    "}\n",
    "\n",
    "for f in fields:\n",
    "    tf = TfidfVectorizer(stop_words='english', min_df=5)\n",
    "    X = tf.fit_transform(df[f])\n",
    "    q = tf.transform([query])\n",
    "    f_score = cosine_similarity(X, q).flatten()\n",
    "    boost = boosts.get(f, 1.0) # if f not in boosts, assign 1\n",
    "    score += boost*f_score \n",
    "\n",
    "score_no_filter = score.copy()\n",
    "\n",
    "for field, value in filters.items():\n",
    "    mask = (df[field] == value).astype(int).values\n",
    "    score *= mask\n",
    "\n",
    "score_with_filter = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0b919a75-f045-416a-aafc-63322c0d214a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>section</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>I’m new to Slack and can’t find the course cha...</td>\n",
       "      <td>Here’s how you join a in Slack: https://slack....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - Can I follow the course after it fini...</td>\n",
       "      <td>Yes, we will keep all the materials after the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - Which playlist on YouTube should I re...</td>\n",
       "      <td>All the main videos are stored in the Main “DA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - What are the prerequisites for this c...</td>\n",
       "      <td>GitHub - DataTalksClub data-engineering-zoomca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>What are the deadlines in this course?</td>\n",
       "      <td>For the 2023 cohort, you can see the deadlines...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        course                           section  \\\n",
       "448  machine-learning-zoomcamp  General course-related questions   \n",
       "7    data-engineering-zoomcamp  General course-related questions   \n",
       "9    data-engineering-zoomcamp  General course-related questions   \n",
       "1    data-engineering-zoomcamp  General course-related questions   \n",
       "453  machine-learning-zoomcamp  General course-related questions   \n",
       "\n",
       "                                              question  \\\n",
       "448  I’m new to Slack and can’t find the course cha...   \n",
       "7    Course - Can I follow the course after it fini...   \n",
       "9    Course - Which playlist on YouTube should I re...   \n",
       "1    Course - What are the prerequisites for this c...   \n",
       "453             What are the deadlines in this course?   \n",
       "\n",
       "                                                  text  \n",
       "448  Here’s how you join a in Slack: https://slack....  \n",
       "7    Yes, we will keep all the materials after the ...  \n",
       "9    All the main videos are stored in the Main “DA...  \n",
       "1    GitHub - DataTalksClub data-engineering-zoomca...  \n",
       "453  For the 2023 cohort, you can see the deadlines...  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 5 results with no filter yields results in 2 different courses\n",
    "idx = np.argsort(-score_no_filter)[:5]\n",
    "df.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4775dc57-f867-4525-bacd-78f3e4c330cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>section</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - Can I follow the course after it fini...</td>\n",
       "      <td>Yes, we will keep all the materials after the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - What are the prerequisites for this c...</td>\n",
       "      <td>GitHub - DataTalksClub data-engineering-zoomca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - What can I do before the course starts?</td>\n",
       "      <td>You can start by installing and setting up all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - how many Zoomcamps in a year?</td>\n",
       "      <td>There are 3 Zoom Camps in a year, as of 2024. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>How can we contribute to the course?</td>\n",
       "      <td>Star the repo! Share it with friends if you fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       course                           section  \\\n",
       "7   data-engineering-zoomcamp  General course-related questions   \n",
       "1   data-engineering-zoomcamp  General course-related questions   \n",
       "4   data-engineering-zoomcamp  General course-related questions   \n",
       "5   data-engineering-zoomcamp  General course-related questions   \n",
       "34  data-engineering-zoomcamp  General course-related questions   \n",
       "\n",
       "                                             question  \\\n",
       "7   Course - Can I follow the course after it fini...   \n",
       "1   Course - What are the prerequisites for this c...   \n",
       "4    Course - What can I do before the course starts?   \n",
       "5              Course - how many Zoomcamps in a year?   \n",
       "34               How can we contribute to the course?   \n",
       "\n",
       "                                                 text  \n",
       "7   Yes, we will keep all the materials after the ...  \n",
       "1   GitHub - DataTalksClub data-engineering-zoomca...  \n",
       "4   You can start by installing and setting up all...  \n",
       "5   There are 3 Zoom Camps in a year, as of 2024. ...  \n",
       "34  Star the repo! Share it with friends if you fi...  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 5 results with a filter yields results in only one course\n",
    "idx = np.argsort(-score_with_filter)[:5]\n",
    "df.iloc[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d29d44-6478-4dee-911e-f38ca0c54336",
   "metadata": {},
   "source": [
    "## Putting it all together using OOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "72f84e5c-c7b8-4c2f-87e1-6214886285ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "class TextSearch:\n",
    "\n",
    "    def __init__(self, text_fields):\n",
    "        self.text_fields = text_fields\n",
    "        self.matrices = {}\n",
    "        self.vectorizers = {}\n",
    "\n",
    "    def fit(self, records, vectorizer_params={}):\n",
    "        self.df = pd.DataFrame(records)\n",
    "\n",
    "        for f in self.text_fields:\n",
    "            tf = TfidfVectorizer(**vectorizer_params)\n",
    "            X = tf.fit_transform(self.df[f])\n",
    "            self.matrices[f] = X\n",
    "            self.vectorizers[f] = tf\n",
    "\n",
    "    def search(self, query, n_results=10, boost={}, filters={}):\n",
    "        score = np.zeros(len(self.df))\n",
    "\n",
    "        for f in self.text_fields:\n",
    "            b = boost.get(f, 1.0)\n",
    "            q = self.vectorizers[f].transform([query])\n",
    "            s = cosine_similarity(self.matrices[f], q).flatten()\n",
    "            score = score + b * s\n",
    "\n",
    "        for field, value in filters.items():\n",
    "            mask = (self.df[field] == value).values\n",
    "            score = score * mask\n",
    "\n",
    "        idx = np.argsort(-score)[:n_results]\n",
    "        results = self.df.iloc[idx]\n",
    "        return results.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "60c14cf8-21ec-47bb-9037-3644c3bbaf73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I still join the course after the start date?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - When will the course start?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I follow the course after it finishes?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'No, late submissions are not allowed. But if the form is still not closed and it’s after the due date, you can still submit the homework. confirm your submission by the date-timestamp on the Course page.y\\nOlder news:[source1] [source2]',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Homework - Are late submissions of homework allowed?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - What can I do before the course starts?',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example:\n",
    "\n",
    "index = TextSearch(\n",
    "    text_fields=['section', 'question', 'text']\n",
    ")\n",
    "index.fit(documents)\n",
    "\n",
    "index.search(\n",
    "    query='I just singned up. Is it too late to join the course?',\n",
    "    n_results=5,\n",
    "    boost={'question': 3.0},\n",
    "    filters={'course': 'data-engineering-zoomcamp'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a098f73c-25c3-4762-966e-6ab0d0b24d4f",
   "metadata": {},
   "source": [
    "# Vector Search\n",
    "\n",
    "Although in this case we get good results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3fffe2-8da8-472c-a60a-db731acd5385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying singular value decomposition -- is dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c5f1d624-16f9-4a28-92a4-e3899dacd696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<948x1333 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 23808 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n",
    "# X has 1333 dimensions. we could reduce this to 16 or something else much smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fee059c4-fbfd-4ae4-98bc-3bfb44af5702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(948, 16)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "X = matrices['text']\n",
    "cv = vectorizers['text']\n",
    "\n",
    "svd = TruncatedSVD(n_components=16)\n",
    "X_emb = svd.fit_transform(X)\n",
    "\n",
    "X_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1129dea5-b2d8-447c-aeab-2ba56d50d18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09653173, -0.08217433, -0.10136631, -0.07843915,  0.06987583,\n",
       "       -0.06062471,  0.03049553, -0.15353354, -0.21979682,  0.28176918,\n",
       "        0.09560222,  0.03190119, -0.09230002, -0.10100939,  0.02032779,\n",
       "        0.02806691])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_emb[0]\n",
    "# instead of a lot of 0s, we have a dense representation (called an 'embedding')\n",
    "# when we reduce the dimensionality, svd tries to preserve as much original information as possible\n",
    "# therefore, synonyms like 'signup' or 'enroll' are grouped together. So in this way we capture the semantic similarities between words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "74567dde-3f41-4df5-bb8a-18ee4340d7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05790198, -0.03845762, -0.05607363, -0.02791455,  0.04109831,\n",
       "       -0.06281215,  0.0168186 , -0.10426521, -0.15233152,  0.17736786,\n",
       "        0.07357216,  0.04177393, -0.06939231, -0.07303331,  0.03184691,\n",
       "        0.01868404])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'I just signed up. Is it too late to join the course?'\n",
    "\n",
    "Q = cv.transform([query]) # creates sparse matrix from Tfidf vectorizer\n",
    "Q_emb = svd.transform(Q) # turn matrix into dense vector\n",
    "Q_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "164b2a1d-b466-44d2-afec-9650c2b31b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007463648268936415"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(X_emb[0], Q_emb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "35191b30-f6e9-4a96-84fb-74c8bb59527d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>section</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>mlops-zoomcamp</td>\n",
       "      <td>+-General course questions</td>\n",
       "      <td>Format for questions: [Problem title]</td>\n",
       "      <td>MLOps Zoomcamp FAQ\\nThe purpose of this docume...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>mlops-zoomcamp</td>\n",
       "      <td>Module 1: Introduction</td>\n",
       "      <td>Is the AWS free tier enough for doing this cou...</td>\n",
       "      <td>For many parts - yes. Some things like kinesis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>mlops-zoomcamp</td>\n",
       "      <td>Module 1: Introduction</td>\n",
       "      <td>For the final project, is it required to be pu...</td>\n",
       "      <td>You can get a few cloud points by using kubern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>Reproducibility</td>\n",
       "      <td>Problem description:\\nDo we have to run everyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>mlops-zoomcamp</td>\n",
       "      <td>Module 5: Monitoring</td>\n",
       "      <td>Found array with 0 sample(s)</td>\n",
       "      <td>Problem description\\nValueError: Found array w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>8. Neural Networks and Deep Learning</td>\n",
       "      <td>The same accuracy on epochs</td>\n",
       "      <td>Problem description\\nThe accuracy and the loss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Environment - I want to use AWS. May I do that?</td>\n",
       "      <td>Yes, you can. Just remember to adapt all the i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>mlops-zoomcamp</td>\n",
       "      <td>Module 3: Orchestration</td>\n",
       "      <td>Problem title</td>\n",
       "      <td>Problem description\\nSolution description\\n(op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>Projects (Midterm and Capstone)</td>\n",
       "      <td>Problem title</td>\n",
       "      <td>Problem description\\nSolution description\\n(op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>Chart for classes and predictions</td>\n",
       "      <td>How to visualize the predictions per classes a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        course                               section  \\\n",
       "810             mlops-zoomcamp            +-General course questions   \n",
       "827             mlops-zoomcamp                Module 1: Introduction   \n",
       "817             mlops-zoomcamp                Module 1: Introduction   \n",
       "779  machine-learning-zoomcamp                         Miscellaneous   \n",
       "925             mlops-zoomcamp                  Module 5: Monitoring   \n",
       "677  machine-learning-zoomcamp  8. Neural Networks and Deep Learning   \n",
       "28   data-engineering-zoomcamp      General course-related questions   \n",
       "892             mlops-zoomcamp               Module 3: Orchestration   \n",
       "755  machine-learning-zoomcamp       Projects (Midterm and Capstone)   \n",
       "791  machine-learning-zoomcamp                         Miscellaneous   \n",
       "\n",
       "                                              question  \\\n",
       "810              Format for questions: [Problem title]   \n",
       "827  Is the AWS free tier enough for doing this cou...   \n",
       "817  For the final project, is it required to be pu...   \n",
       "779                                    Reproducibility   \n",
       "925                       Found array with 0 sample(s)   \n",
       "677                        The same accuracy on epochs   \n",
       "28     Environment - I want to use AWS. May I do that?   \n",
       "892                                      Problem title   \n",
       "755                                      Problem title   \n",
       "791                  Chart for classes and predictions   \n",
       "\n",
       "                                                  text  \n",
       "810  MLOps Zoomcamp FAQ\\nThe purpose of this docume...  \n",
       "827  For many parts - yes. Some things like kinesis...  \n",
       "817  You can get a few cloud points by using kubern...  \n",
       "779  Problem description:\\nDo we have to run everyt...  \n",
       "925  Problem description\\nValueError: Found array w...  \n",
       "677  Problem description\\nThe accuracy and the loss...  \n",
       "28   Yes, you can. Just remember to adapt all the i...  \n",
       "892  Problem description\\nSolution description\\n(op...  \n",
       "755  Problem description\\nSolution description\\n(op...  \n",
       "791  How to visualize the predictions per classes a...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = cosine_similarity(X_emb, Q_emb).flatten()\n",
    "idx = np.argsort(-score)[:10]\n",
    "df.loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "66269428-d5af-47d9-94a4-97b78a095390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# benefits of embedments: this is that we take care of synonyms\n",
    "# cons: more difficult to interpret results. however we can improve this by using NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6b3d65b2-6d56-43e0-9f72-ae81a1d582cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00510061, 0.00554213, 0.        , 0.        , 0.08543621,\n",
       "       0.        , 0.0011603 , 0.        , 0.00388182, 0.01179882,\n",
       "       0.        , 0.        , 0.        , 0.00873678, 0.00501248,\n",
       "       0.00924685])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "nmf = NMF(n_components=16)\n",
    "X_emb = nmf.fit_transform(X)\n",
    "X_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "735a2794-ef35-4d1f-8087-d5c66d281d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMF creates 'clusters' of different topics, and non zero values can be seen as the query being related to those 2 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a9d9c44b-e9ee-46cc-840c-58d54b6a53c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00591907, 0.00600601, 0.        , 0.0036612 , 0.04048327,\n",
       "       0.        , 0.        , 0.        , 0.00073802, 0.00062452,\n",
       "       0.        , 0.        , 0.        , 0.0104604 , 0.00982633,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = cv.transform([query])\n",
    "Q_emb = nmf.transform(Q)\n",
    "Q_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d66693e1-3c31-4053-a7a5-8f4a8a17606a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>section</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - When will the course start?</td>\n",
       "      <td>The purpose of this document is to capture fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>I just joined. What should I do next? How can ...</td>\n",
       "      <td>Welcome to the course! Go to the course page (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Submitting learning in public links</td>\n",
       "      <td>When you post about what you learned from the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>Projects (Midterm and Capstone)</td>\n",
       "      <td>How to conduct peer reviews for projects?</td>\n",
       "      <td>Answer: Previous cohorts projects page has ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>The course has already started. Can I still jo...</td>\n",
       "      <td>Yes, you can. You won’t be able to submit some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>Any advice for adding the Machine Learning Zoo...</td>\n",
       "      <td>I’ve seen LinkedIn users list DataTalksClub as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Homework and Leaderboard - what is the system ...</td>\n",
       "      <td>After you submit your homework it will be grad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>Is there a way to serve up a form for users to...</td>\n",
       "      <td>Yes, you can create a mobile app or interface ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>Projects (Midterm and Capstone)</td>\n",
       "      <td>What modules, topics, problem-sets should a mi...</td>\n",
       "      <td>Answer: Ideally midterms up to module-06, caps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Homework - What are homework and project deadl...</td>\n",
       "      <td>You can find the latest and up-to-date deadlin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        course                           section  \\\n",
       "0    data-engineering-zoomcamp  General course-related questions   \n",
       "452  machine-learning-zoomcamp  General course-related questions   \n",
       "456  machine-learning-zoomcamp  General course-related questions   \n",
       "760  machine-learning-zoomcamp   Projects (Midterm and Capstone)   \n",
       "449  machine-learning-zoomcamp  General course-related questions   \n",
       "809  machine-learning-zoomcamp                     Miscellaneous   \n",
       "17   data-engineering-zoomcamp  General course-related questions   \n",
       "772  machine-learning-zoomcamp                     Miscellaneous   \n",
       "758  machine-learning-zoomcamp   Projects (Midterm and Capstone)   \n",
       "14   data-engineering-zoomcamp  General course-related questions   \n",
       "\n",
       "                                              question  \\\n",
       "0                 Course - When will the course start?   \n",
       "452  I just joined. What should I do next? How can ...   \n",
       "456                Submitting learning in public links   \n",
       "760          How to conduct peer reviews for projects?   \n",
       "449  The course has already started. Can I still jo...   \n",
       "809  Any advice for adding the Machine Learning Zoo...   \n",
       "17   Homework and Leaderboard - what is the system ...   \n",
       "772  Is there a way to serve up a form for users to...   \n",
       "758  What modules, topics, problem-sets should a mi...   \n",
       "14   Homework - What are homework and project deadl...   \n",
       "\n",
       "                                                  text  \n",
       "0    The purpose of this document is to capture fre...  \n",
       "452  Welcome to the course! Go to the course page (...  \n",
       "456  When you post about what you learned from the ...  \n",
       "760  Answer: Previous cohorts projects page has ins...  \n",
       "449  Yes, you can. You won’t be able to submit some...  \n",
       "809  I’ve seen LinkedIn users list DataTalksClub as...  \n",
       "17   After you submit your homework it will be grad...  \n",
       "772  Yes, you can create a mobile app or interface ...  \n",
       "758  Answer: Ideally midterms up to module-06, caps...  \n",
       "14   You can find the latest and up-to-date deadlin...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = cosine_similarity(X_emb, Q_emb).flatten()\n",
    "idx = np.argsort(-score)[:10]\n",
    "df.loc[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614f8283-5e0a-4542-9692-676a72371d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSearch:\n",
    "\n",
    "    def __init__(self, text_fields):\n",
    "        self.text_fields = text_fields\n",
    "        self.matrices = {}\n",
    "        self.vectorizers = {}\n",
    "        self.embedders = {}\n",
    "\n",
    "    def fit(self, records, vectorizer_params={}):\n",
    "        self.df = pd.DataFrame(records)\n",
    "\n",
    "        for f in self.text_fields:\n",
    "            tf = TfidfVectorizer(**vectorizer_params)\n",
    "            X = tf.fit_transform(self.df[f])\n",
    "            \n",
    "\n",
    "            self.vectorizers[f] = tf\n",
    "\n",
    "            svd = ...\n",
    "            svd.fit_transform(...)\n",
    "            self.matrices[f] = X_emb\n",
    "            self.embedders[f] = svd\n",
    "\n",
    "            \n",
    "    def search(self, query, n_results=10, boost={}, filters={}):\n",
    "    score = np.zeros(len(self.df))\n",
    "\n",
    "    for f in self.text_fields:\n",
    "        b = boost.get(f, 1.0)\n",
    "        q = self.vectorizers[f].transform([query])\n",
    "        s = cosine_similarity(self.matrices[f], q).flatten()\n",
    "        score = score + b * s\n",
    "\n",
    "    for field, value in filters.items():\n",
    "        mask = (self.df[field] == value).values\n",
    "        score = score * mask\n",
    "\n",
    "    idx = np.argsort(-score)[:n_results]\n",
    "    results = self.df.iloc[idx]\n",
    "    return results.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fff904-285e-4ffd-b984-11b75fead4f9",
   "metadata": {},
   "source": [
    "issues: the source is Bag of Words, which loses information of the word order, which can be important in many cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc0dcd1-1b49-4ba5-a823-6f6d207de843",
   "metadata": {},
   "source": [
    "## BERT\n",
    "NN that turns a document into an embedding. Captures not only semantic similarity but also word order. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "45aa8020-511f-4cbf-9d40-db2872b09b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "# loading tokenizer and pre-trained model\n",
    "# tokenizer turns text into a numerical representation\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "model.eval()  # Set the model to evaluation mode if not training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7e2e84fd-8e6f-4b3b-b181-d70eed14e8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2748,  1010,  2057,  2097,  2562,  2035,  1996,  4475,  2044,\n",
       "          1996,  2607, 12321,  1012,   102],\n",
       "        [  101,  2017,  2064,  3582,  1996,  2607,  2012,  2115,  2219,  6393,\n",
       "          2044,  2009, 12321,   102,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Yes, we will keep all the materials after the course finishes.\",\n",
    "    \"You can follow the course at your own pace after it finishes\"\n",
    "]\n",
    "encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "db32fbc5-c3e7-4752-aca0-01c9be60955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # Disable gradient calculation for inference\n",
    "    outputs = model(**encoded_input)\n",
    "    hidden_states = outputs.last_hidden_state # contains embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "851a9273-febf-480e-bb42-7b3ea5a93cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 15, 768])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states.shape\n",
    "# 2 is num. documens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "03a1803c-d8fb-45e9-965a-867142674f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1010,  0.0181,  0.1303,  ..., -0.2932,  0.1863,  0.6615],\n",
       "        [ 1.0608, -0.1242,  0.1370,  ..., -0.1605,  1.0429,  0.3532],\n",
       "        [ 0.1802,  0.0776,  0.3941,  ..., -0.1379,  0.5974,  0.1704],\n",
       "        ...,\n",
       "        [ 0.4738, -0.0184,  0.2186,  ..., -0.0013, -0.0833, -0.2170],\n",
       "        [ 0.6516,  0.1216, -0.2494,  ...,  0.1557, -0.5632, -0.4310],\n",
       "        [ 0.7164,  0.2157, -0.0281,  ...,  0.2281, -0.6725, -0.3245]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "61fda83c-9c49-47ad-bb4f-9d8b40dc3f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings = hidden_states.mean(dim=1)\n",
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d9e2e7f4-620a-4970-be55-fe74b68506e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3600, -0.1607,  0.3545,  ...,  0.0429,  0.0348, -0.0382],\n",
       "        [ 0.1785, -0.5000,  0.2528,  ..., -0.1141, -0.3361,  0.4110]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "910c1919-b465-40e7-8f35-b9a3dc7e5dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_emb = sentence_embeddings.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5a03e66f-c81b-4db8-aa13-abd7eadbece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batches(seq, n):\n",
    "    result = []\n",
    "    for i in range(0, len(seq), n):\n",
    "        batch = seq[i:i+n]\n",
    "        result.append(batch)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fbc4a7-eaa0-4791-946c-e18f8c4e1a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▎      | 20/119 [02:08<10:38,  6.44s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "texts = df['text'].tolist()\n",
    "text_batches = make_batches(texts, 8)\n",
    "\n",
    "all_embeddings = []\n",
    "\n",
    "for batch in tqdm(text_batches):\n",
    "    encoded_input = tokenizer(batch, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoded_input)\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "        \n",
    "        batch_embeddings = hidden_states.mean(dim=1)\n",
    "        batch_embeddings_np = batch_embeddings.cpu().numpy()\n",
    "        all_embeddings.append(batch_embeddings_np)\n",
    "\n",
    "final_embeddings = np.vstack(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a5da646d-a822-4188-9908-747c27d4b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings(texts, batch_size=8):\n",
    "    text_batches = make_batches(texts, 8)\n",
    "    \n",
    "    all_embeddings = []\n",
    "    \n",
    "    for batch in tqdm(text_batches):\n",
    "        encoded_input = tokenizer(batch, padding=True, truncation=True, return_tensors='pt')\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encoded_input)\n",
    "            hidden_states = outputs.last_hidden_state\n",
    "            \n",
    "            batch_embeddings = hidden_states.mean(dim=1)\n",
    "            batch_embeddings_np = batch_embeddings.cpu().numpy()\n",
    "            all_embeddings.append(batch_embeddings_np)\n",
    "    \n",
    "    final_embeddings = np.vstack(all_embeddings)\n",
    "    return final_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ed2d0701-8e2f-4d62-8a4e-a20f2a9ba0f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_batches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[117], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_text \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[116], line 2\u001b[0m, in \u001b[0;36mcompute_embeddings\u001b[0;34m(texts, batch_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_embeddings\u001b[39m(texts, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     text_batches \u001b[38;5;241m=\u001b[39m \u001b[43mmake_batches\u001b[49m(texts, \u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m      4\u001b[0m     all_embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(text_batches):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'make_batches' is not defined"
     ]
    }
   ],
   "source": [
    "X_text = compute_embeddings(df['text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff42708-f015-4bda-985d-b9aebe3a6d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
